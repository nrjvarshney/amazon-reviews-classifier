{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# clear cache from CUDA\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Score\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights for computing classification loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = df[\"Score\"].value_counts()/df.shape[0]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.tensor([0.091948, 0.052368, 0.075010, 0.141885, 0.638789]).to(device)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df, split_ratio= 0.8):\n",
    "    train=df.sample(frac=split_ratio,random_state=200)\n",
    "    test=df.drop(train.index)\n",
    "    print(\"Number of Training Samples: \", len(train))\n",
    "    print(\"Number of Validation Samples: \", len(test))\n",
    "    return(train, test)\n",
    "train_df, test_df = split_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters = {\n",
    "    \"batch_size\": 8,\n",
    "    \"epochs\": 4,\n",
    "    \"output_folder\": \"./Amazon_review_classider_models/\",\n",
    "    \"output_file\": \"model.dat\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        review_text =  self.df.iloc[index][\"Text\"]\n",
    "        # we will subtract 1 from the label so that classes are 0 to 4 instead of 1 to 5\n",
    "        review_score = self.df.iloc[index][\"Score\"] - 1\n",
    "        return review_text, review_score\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "train_dataset = AmazonDataset(train_df)\n",
    "test_dataset = AmazonDataset(test_df)\n",
    "train_dataloader = DataLoader(dataset = train_dataset, batch_size = training_parameters[\"batch_size\"], shuffle = True, num_workers = 2)\n",
    "test_dataloader = DataLoader(dataset = test_dataset, batch_size = training_parameters[\"batch_size\"], shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "class AmazonClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(AmazonClassifier, self).__init__()\n",
    "        num_labels = config[\"num_labels\"]\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(config[\"hidden_dropout_prob\"])\n",
    "        self.classifier = nn.Linear(config[\"hidden_size\"],num_labels)\n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        \n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        return logits.to(device)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize raw input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_for_model(inputs, labels):\n",
    "    input_ids_list = []\n",
    "    attention_masks_list = []\n",
    "    token_type_ids_list = []\n",
    "    for input_review in inputs:\n",
    "\n",
    "        encoded_input = tokenizer.encode_plus(\n",
    "            input_review,\n",
    "            add_special_tokens=True,\n",
    "            max_length= config[\"max_length\"],\n",
    "            pad_to_max_length=True,\n",
    "            return_overflowing_tokens=True,\n",
    "        )\n",
    "        if \"num_truncated_tokens\" in encoded_input and encoded_input[\"num_truncated_tokens\"] > 0:\n",
    "            print(\"Attention! you are cropping tokens\")\n",
    "\n",
    "        input_ids_list.append(encoded_input[\"input_ids\"])\n",
    "        attention_masks_list.append(\n",
    "            encoded_input[\"attention_mask\"] if \"attention_mask\" in encoded_input else None\n",
    "        )\n",
    "        token_type_ids_list.append(\n",
    "            encoded_input[\"token_type_ids\"] if \"token_type_ids\" in encoded_input else None\n",
    "        )\n",
    "\n",
    "\n",
    "    inputs = {\n",
    "        \"input_ids\": torch.tensor(input_ids_list),\n",
    "        \"attention_mask\": torch.tensor(attention_masks_list),\n",
    "        \"token_type_ids\": torch.tensor(token_type_ids_list),\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer accuracy for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(logits, labels):\n",
    "    predicted_label = logits.max(dim = 1)[1]\n",
    "\n",
    "    acc = (predicted_label == labels).float().mean()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation after every epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Config variables \n",
    "\n",
    "config = {\n",
    "    \"num_labels\": 5,\n",
    "    \"hidden_dropout_prob\": 0.15,\n",
    "    \"hidden_size\": 768,\n",
    "    \"max_length\": 400,\n",
    "}\n",
    "\n",
    "model = AmazonClassifier(config)\n",
    "model.to(device)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "loss_func = nn.NLLLoss(weight=weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 2e-5)\n",
    "\n",
    "best_accuracy = 0.0\n",
    "softmax_func = nn.LogSoftmax(dim=1)\n",
    "\n",
    "for epoch in range(training_parameters[\"epochs\"]):\n",
    "    model.train()\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        if(i%1000 == 0):\n",
    "            print(\"Training \"+ str(i))\n",
    "        '''\n",
    "        inputs are reviews of the batch\n",
    "        labels are scores of the batch\n",
    "        '''\n",
    "        inputs = get_input_for_model(inputs, labels)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = inputs[\"labels\"]\n",
    "        logits = model(**inputs)\n",
    "        \n",
    "        loss = loss_func(softmax_func(logits), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    # test after each epoch\n",
    "    model.eval()\n",
    "    mean_loss = 0.0\n",
    "    mean_accuracy = 0.0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(test_dataloader):\n",
    "            inputs = get_input_for_model(inputs, labels)\n",
    "            labels = inputs[\"labels\"]\n",
    "\n",
    "            logits = model(inputs)\n",
    "            loss = loss_func(softmax_func(logits), labels)\n",
    "            accuracy = compute_accuracy(nn.LogSoftmax(logits, dim=1), labels)\n",
    "            mean_loss += loss\n",
    "            mean_accuracy += accuracy\n",
    "            count += 1\n",
    "        mean_accuracy /= count\n",
    "        mean_loss /= count\n",
    "    \n",
    "    if(mean_accuracy > best_accuracy):\n",
    "        best_accuracy = mean_accuracy\n",
    "        torch.save(model.state_dict(), os.path.join(training_parameters[\"outputFolder\"], config[\"output_file\"] + \"_valTested_\" + str(best_acc)))\n",
    "        \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
